{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/Quantum-GANs/blob/main/Visualised_Circuit_Quantum_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports + Preamble"
      ],
      "metadata": {
        "id": "Vk1aXXB97Amb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5d3UZ7FGU8w",
        "outputId": "3bf7dd87-f639-4bf9-f467-4544989833bc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.40 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.40.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.40->pennylane) (0.3.29.0.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "!pip install pennylane\n",
        "import pennylane as qml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxMcVhHZJqQN",
        "outputId": "33bdd9a6-06ee-4cad-bb16-0aa2a37d77b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the random seed for reproducibility"
      ],
      "metadata": {
        "id": "Stf86xUe2ULF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "KzdGW-v92TeF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Data Loading + Pre-Processing\n",
        "\n",
        "a) Create class that does the loading and pre-processing of the MNIST data\n",
        "\n",
        "b) create class instance to load in the MNIST data\n",
        "\n",
        "c) create data loader object"
      ],
      "metadata": {
        "id": "EsZ-epQ52YVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1a) Create class that does the loading and pre-processing of the MNIST data\n",
        "\n",
        "- `__init__`: stores MNIST filepath, data transformation and filtered MNIST dataframe\n",
        "- `filter_by_label`: filters for images with the label = [insert [0,9] label]\n",
        "- `__len__`: returns total number of images in the filtered dataset\n",
        "- `__getitem__`: retrieves specific image and its label from the dataset based on the provided index. It normalises pixel values, reshapes the image, applies any specified transformations & returns the processed image and label"
      ],
      "metadata": {
        "id": "AnTmL2PH2uaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitsDataset(Dataset):\n",
        "    \"\"\"Pytorch dataloader for the Optical Recognition of Handwritten Digits Data Set\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, label=0, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            label (int [0,9], optional): Filter for MNIST images with said specified label.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "            \"\"\"\n",
        "        self.csv_file = csv_file\n",
        "        self.transform = transform\n",
        "        self.df = self.filter_by_label(label)\n",
        "\n",
        "    def filter_by_label(self, label):\n",
        "        # Use pandas to return a dataframe of only zeros\n",
        "        df = pd.read_csv(self.csv_file)\n",
        "        df = df.loc[df.iloc[:, -1] == label]\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = self.df.iloc[idx, :-1] / 16\n",
        "        image = np.array(image)\n",
        "        image = image.astype(np.float32).reshape(8, 8)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Return image and label\n",
        "        return image, 0"
      ],
      "metadata": {
        "id": "HJ8SAMtyGiMX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) create class instance to load in the MNIST data\n",
        "This data is filtered by the label kwarg in the DigitDataset class"
      ],
      "metadata": {
        "id": "39NfGu8wCsnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_to_pytorch_tensor = transforms.Compose([transforms.ToTensor()])\n",
        "'''\n",
        "dataset = DigitsDataset(\n",
        "    csv_file = \"/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/3. Quantum/quantum_gan_project/MNIST_images.tra\",\n",
        "    transform = transform_to_pytorch_tensor\n",
        ")\n",
        "'''\n",
        "dataset = DigitsDataset(\n",
        "    csv_file = \"/content/drive/MyDrive/Quantum_data/optdigits.tra\",\n",
        "    label = 0,\n",
        "    transform = transform_to_pytorch_tensor\n",
        ")"
      ],
      "metadata": {
        "id": "R9DB1blcIQ9F"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "see what's in our class instance"
      ],
      "metadata": {
        "id": "B8zMwPqZBwUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "964z9cFsB2cf",
        "outputId": "ce55a366-988b-44af-a17d-83a40e6bdcb6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.6250, 1.0000, 0.3750, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.4375, 1.0000, 0.5000, 1.0000, 0.3125, 0.0000, 0.0000],\n",
              "          [0.0000, 0.6875, 1.0000, 0.0000, 0.3750, 0.8750, 0.1875, 0.0000],\n",
              "          [0.0000, 0.7500, 0.7500, 0.0000, 0.0000, 0.6875, 0.6875, 0.0000],\n",
              "          [0.0000, 0.7500, 0.7500, 0.0000, 0.0000, 0.5000, 0.7500, 0.0000],\n",
              "          [0.0000, 0.4375, 0.9375, 0.0625, 0.0000, 0.8125, 0.6875, 0.0000],\n",
              "          [0.0000, 0.0000, 1.0000, 0.5000, 0.6250, 0.9375, 0.1875, 0.0000],\n",
              "          [0.0000, 0.0000, 0.6250, 1.0000, 0.9375, 0.1875, 0.0000, 0.0000]]]),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the above output we can see the feature map and the label"
      ],
      "metadata": {
        "id": "SAR0HLfTGHNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "display the first 8 images in the dataset class instance"
      ],
      "metadata": {
        "id": "Lsd2Z3kUDMY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE= 8\n",
        "reshaped_image_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
        "\n",
        "plt.figure(figsize=(8,2))\n",
        "\n",
        "for i in range(8):\n",
        "    image = dataset[i][0].reshape(reshaped_image_shape)\n",
        "    plt.subplot(1, 8, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image.numpy(), cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "DD3SLOH_DLmM",
        "outputId": "c96d6d2b-1c0d-48c9-f6f9-a2fed6579c0b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x200 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to change the digits printed, change the label kwarg in the DigitDataset class"
      ],
      "metadata": {
        "id": "UUUOK8zaHKZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) create data loader object\n",
        "\n",
        "dataloaders efficiently load date in batches during training"
      ],
      "metadata": {
        "id": "51EJy9vUGQxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    drop_last = True\n",
        ")"
      ],
      "metadata": {
        "id": "oG-T9naRCdoP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building\n",
        "\n",
        "a) Build class for the classical discriminator\n",
        "\n",
        "b) Building the quantum generator\n",
        "- i) define the quantum variables\n",
        "- ii) define the quantum device\n",
        "- iii) define the qunatum circuit\n",
        "- iv) define the partial measurement process\n",
        "- v) create quantum generator class to use during training"
      ],
      "metadata": {
        "id": "3o5ceqNUG8tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2a) Build class for the classical discriminator\n",
        "\n",
        "- fully connected NN with two hidden layers\n",
        "- sigmoid output => probability of an input being classified as real"
      ],
      "metadata": {
        "id": "lRW_ZMRMHyhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Fully connected classical discriminator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__() # calls the constructer of the parent class (nn.Module)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Inputs to first hidden layer (num_input_features -> 64)\n",
        "            nn.Linear(IMAGE_SIZE * IMAGE_SIZE, 64),\n",
        "            nn.ReLU(),\n",
        "            # First hidden layer (64 -> 16)\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            # Second hidden layer (16 -> output)\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "YKMfcs35J3wi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2b) building the quantum generator\n",
        "\n",
        "Quantum generator consists of `n_generators` sub-generators, each comprised of `n_qubits` qubits\n",
        "\n",
        "Sub-generator circuit architecture:\n",
        "\n",
        "<img src=\"https://pennylane.ai/_images/qcircuit.jpeg\" width=\"500\">\n",
        "\n",
        "---\n",
        "\n",
        "i) **state embedding**: a latent vector, $z \\in \\mathbb{R}^N$, is sampled from a uniform distn in the interval $[0, \\pi/2)$ and sent to all sub-generators\n",
        "\n",
        "$z$ --> $|z\\rangle$ (state embedding) by applying the RY gates. Each element of z determines the rotation angle of the RY gate.\n",
        "\n",
        "---\n",
        "\n",
        "ii) **parameterised layers**: a set of parameterised RY gates apply LINEAR (because they're unitary) TRANSFORMATIONS to the quantum state, followed by control Z gates (to introduce entanglement). This layer is repeated `q_depth` times.\n",
        "\n",
        "---\n",
        "\n",
        "iii) **Non-linear transform**: For non-simple generative tasks we need a non-linearity.\n",
        "\n",
        "Ancillary qubits and partial measurements are used to introduce NON-LINEARITY.\n",
        "\n",
        "Partial measurement: measure ONLY the ancillary qubits. This collapses them into classical values. We don't care about those values though so just discard them.\n",
        "\n",
        "The act of measuring the ancillary qubits and collapsing them to classical values forces a non-linear transformation on the remaining qubits. We then measure these remaining qubits to obtain sub-generator output $\\boldsymbol{g^{(i)}}$, the output for a given patch of pixels. Normalisation, causes the sum of all its elements to sum to 1\n",
        "\n",
        "---\n",
        "\n",
        "iv) **post processing**: all the elements summing to one makes it difficult to map them to pixel intensities\n",
        "\n",
        "$\\tilde{x}(i) = \\frac{g(i)}{\\max_k g(i)_k}$\n",
        "\n",
        "this solves the issue by scaling it so the largest values becomes 1 and all other values scale proportionally\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tGFyFTxJKUUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) i) define quantum variables - as per the diagram in the above markdown"
      ],
      "metadata": {
        "id": "LdjmV6ldb7In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#values used in example (for ease of reseting =5,1,6,4 respectively)\n",
        "n_qubits = 5\n",
        "n_a_qubits = 1\n",
        "q_depth = 6\n",
        "n_generators = 4"
      ],
      "metadata": {
        "id": "J569xl1mJ3yt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) ii) define the quantum device"
      ],
      "metadata": {
        "id": "0CBCslgkcrcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "\n",
        "# Enable CUDA device if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kum6J7AnJ304",
        "outputId": "5fadaab0-14e2-4ffb-dd3e-86028547b565"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) iii) define the quantum circuit"
      ],
      "metadata": {
        "id": "r4nvaFV7dl6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, diff_method=\"parameter-shift\") # recall the parameter shift differentiation method from lectures, differentiation needed for backprop\n",
        "def quantum_circuit(noise, weights):\n",
        "\n",
        "    weights = weights.reshape(q_depth, n_qubits)\n",
        "\n",
        "    # State embedding\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(noise[i], wires=i)\n",
        "\n",
        "    # Repeated layer\n",
        "    for i in range(q_depth):\n",
        "        # Parameterised layer\n",
        "        for y in range(n_qubits):\n",
        "            qml.RY(weights[i][y], wires=y)\n",
        "\n",
        "        # Control Z gates\n",
        "        for y in range(n_qubits - 1):\n",
        "            qml.CZ(wires=[y, y + 1])\n",
        "\n",
        "    return qml.probs(wires=list(range(n_qubits)))"
      ],
      "metadata": {
        "id": "ikXIuHasJ32z"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ignore noise and weight here they are just so we can visualise the circuit\n",
        "#we input them properly in the generator forward pass\n",
        "noise = np.random.uniform(0, 2 * np.pi, size=n_qubits)\n",
        "weights = np.random.uniform(0, 2 * np.pi, size=(q_depth, n_qubits))\n",
        "\n",
        "test_circuit = quantum_circuit(noise,weights)\n",
        "\n",
        "qml.drawer.use_style(\"black_white\")\n",
        "qml.draw_mpl(quantum_circuit)(noise,weights)"
      ],
      "metadata": {
        "id": "LdNmlPXz43CY",
        "outputId": "eb4796eb-8d7b-4ef9-e53a-323e2ffaecbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WireError",
          "evalue": "Cannot run circuit(s) on lightning.qubit as they contain wires not found on the device: {1, 2, 3, 4}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWireError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-af697ee70b5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantum_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"black_white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcapture_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_classical_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         res = qml.execute(\n\u001b[0m\u001b[1;32m    882\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, transform_program, inner_transform, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, device_vjp, mcm_config, gradient_fn)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mno_interface_boundary_required\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36minner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_post_processing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/transforms/core/transform_program.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margnums\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0mnew_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m                 \u001b[0mexecution_tapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/devices/preprocess.py\u001b[0m in \u001b[0;36mvalidate_device_wires\u001b[0;34m(tape, wires, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextra_wires\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             raise WireError(\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;34mf\"Cannot run circuit(s) on {name} as they contain wires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;34mf\"not found on the device: {extra_wires}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWireError\u001b[0m: Cannot run circuit(s) on lightning.qubit as they contain wires not found on the device: {1, 2, 3, 4}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) iv) define the partial measurement process"
      ],
      "metadata": {
        "id": "ti2hLBDVdxxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partial_measure(noise, weights):\n",
        "    # Non-linear Transform\n",
        "    probs = quantum_circuit(noise, weights)\n",
        "    probsgiven0 = probs[: (2 ** (n_qubits - n_a_qubits))]\n",
        "    probsgiven0 /= torch.sum(probs)\n",
        "\n",
        "    # Post-Processing\n",
        "    probsgiven = probsgiven0 / torch.max(probsgiven0)\n",
        "    return probsgiven"
      ],
      "metadata": {
        "id": "PjK8QVbrdxMV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) v) create a quantum generator class to use during training\n",
        "\n",
        "- `__init__`: initialises the quantum generator, holds container for the learnable weights that will updated during training (`self.q_params`)\n",
        "- `forward`: iterates over `self.q_params` list which contains the paramters for each sub-generator used to generate the output patches, the patches are concatenated together to form a full image"
      ],
      "metadata": {
        "id": "claNHS8qeeT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchQuantumGenerator(nn.Module):\n",
        "    \"\"\"Quantum generator class for the patch method\"\"\"\n",
        "\n",
        "    def __init__(self, n_generators, q_delta=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_generators (int): Number of sub-generators to be used in the patch method.\n",
        "            q_delta (float, optional): Spread of the random distribution for parameter initialisation.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.q_params = nn.ParameterList(\n",
        "            [\n",
        "                nn.Parameter(q_delta * torch.rand(q_depth * n_qubits), requires_grad=True)\n",
        "                for _ in range(n_generators)\n",
        "            ]\n",
        "        )\n",
        "        self.n_generators = n_generators\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        # Initialise empty pytorch Tensor to store the generated images - x.size(0) is the batch size.\n",
        "        images = torch.Tensor(input_batch.size(0), 0).to(device)\n",
        "\n",
        "        # Iterate over all sub-generators\n",
        "        for params in self.q_params:\n",
        "\n",
        "            # Create a Tensor to 'catch' a batch of the patches from a single sub-generator\n",
        "            PATCH_SIZE = 2 ** (n_qubits - n_a_qubits)\n",
        "            patches = torch.Tensor(0, PATCH_SIZE).to(device) # initialise empty pytorch tensor to store the generated patches\n",
        "            for elem in input_batch:\n",
        "                q_out = partial_measure(elem, params).float().unsqueeze(0)\n",
        "                patches = torch.cat((patches, q_out))\n",
        "\n",
        "            # Each batch of patches is concatenated with each other to create a batch of images\n",
        "            images = torch.cat((images, patches), 1)\n",
        "\n",
        "        return images"
      ],
      "metadata": {
        "id": "KNN-JD7nJ342"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Training + Evaluation\n",
        "\n",
        "a) define learning rates and number of training iterations\n",
        "\n",
        "b) execute training process\n",
        "\n",
        "c) evaluation: plot how the generated images evolved throughout training"
      ],
      "metadata": {
        "id": "6aWLSLqMekl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3a) define learning rates and number of training iterations"
      ],
      "metadata": {
        "id": "wxquusP8erje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lrG = 0.3  # Learning rate for the generator\n",
        "lrD = 0.01  # Learning rate for the discriminator\n",
        "num_iter = 500  # Number of training iterations"
      ],
      "metadata": {
        "id": "WYu1hzGVJ367"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3b) Execute training process"
      ],
      "metadata": {
        "id": "R6RG8MTbfH-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator().to(device)\n",
        "generator = PatchQuantumGenerator(n_generators).to(device)\n",
        "\n",
        "# Binary cross entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimisers - stochastic grad descent\n",
        "optD = optim.SGD(discriminator.parameters(), lr=lrD)\n",
        "optG = optim.SGD(generator.parameters(), lr=lrG)\n",
        "\n",
        "real_labels = torch.full((BATCH_SIZE,), 1.0, dtype=torch.float, device=device)\n",
        "fake_labels = torch.full((BATCH_SIZE,), 0.0, dtype=torch.float, device=device)\n",
        "\n",
        "# Fixed noise allows us to visually track the generated images throughout training\n",
        "fixed_noise = torch.rand(8, n_qubits, device=device) * math.pi / 2\n",
        "\n",
        "# Iteration counter\n",
        "counter = 0\n",
        "\n",
        "# Collect images for plotting later\n",
        "results = []\n",
        "\n",
        "while True:\n",
        "    for i, (data, _) in enumerate(dataloader):\n",
        "\n",
        "        # Data for training the discriminator\n",
        "        data = data.reshape(-1, IMAGE_SIZE * IMAGE_SIZE)\n",
        "        real_data = data.to(device)\n",
        "\n",
        "        # Noise follwing a uniform distribution in range [0,pi/2)\n",
        "        noise = torch.rand(BATCH_SIZE, n_qubits, device=device) * math.pi / 2\n",
        "        fake_data = generator(noise)\n",
        "\n",
        "        # Training the discriminator\n",
        "        discriminator.zero_grad()\n",
        "        outD_real = discriminator(real_data).view(-1)\n",
        "        outD_fake = discriminator(fake_data.detach()).view(-1)\n",
        "\n",
        "        errD_real = criterion(outD_real, real_labels)\n",
        "        errD_fake = criterion(outD_fake, fake_labels)\n",
        "        # Propagate gradients\n",
        "        errD_real.backward()\n",
        "        errD_fake.backward()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        optD.step()\n",
        "\n",
        "        # Training the generator\n",
        "        generator.zero_grad()\n",
        "        outD_fake = discriminator(fake_data).view(-1)\n",
        "        errG = criterion(outD_fake, real_labels)\n",
        "        errG.backward()\n",
        "        optG.step()\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "        # Show loss values\n",
        "        if counter % 10 == 0:\n",
        "            print(f'Iteration: {counter}, Discriminator Loss: {errD:0.3f}, Generator Loss: {errG:0.3f}')\n",
        "            test_images = generator(fixed_noise).view(8,1,IMAGE_SIZE,IMAGE_SIZE).cpu().detach()\n",
        "\n",
        "            # Save images every 50 iterations\n",
        "            if counter % 50 == 0:\n",
        "                results.append(test_images)\n",
        "\n",
        "        if counter == num_iter:\n",
        "            break\n",
        "    if counter == num_iter:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rqb8PyqyJ386",
        "outputId": "6900f827-f050-4bee-c550-5fff9718ae37"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x4 and 64x64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-327f919aba49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutD_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-bdd621287d20>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 64x64)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3c) plot how the generated imgaes evolved throughout training"
      ],
      "metadata": {
        "id": "HTVIp1tzfc5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 5))\n",
        "outer = gridspec.GridSpec(5, 2, wspace=0.1)\n",
        "\n",
        "for i, images in enumerate(results):\n",
        "    inner = gridspec.GridSpecFromSubplotSpec(1, images.size(0),\n",
        "                    subplot_spec=outer[i])\n",
        "\n",
        "    images = torch.squeeze(images, dim=1)\n",
        "    for j, im in enumerate(images):\n",
        "\n",
        "        ax = plt.Subplot(fig, inner[j])\n",
        "        ax.imshow(im.numpy(), cmap=\"gray\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        if j==0:\n",
        "            ax.set_title(f'Iteration {50+i*50}', loc='left')\n",
        "        fig.add_subplot(ax)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XmT9z1RhJ3-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvSSPSkkJ4BA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}