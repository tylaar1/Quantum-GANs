{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/Quantum-GANs/blob/main/BaseModel_Quantum_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk1aXXB97Amb"
      },
      "source": [
        "# Imports + Preamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c5d3UZ7FGU8w",
        "outputId": "c91a4698-6606-4a47-8780-c915076961c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# !pip install pennylane\n",
        "import pennylane as qml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxMcVhHZJqQN",
        "outputId": "8f9c7d20-86f8-43a1-9e62-c4e248b4ccb2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stf86xUe2ULF"
      },
      "source": [
        "Set the random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KzdGW-v92TeF"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsZ-epQ52YVO"
      },
      "source": [
        "# 1) Data Loading + Pre-Processing\n",
        "\n",
        "a) Create class that does the loading and pre-processing of the MNIST data\n",
        "\n",
        "b) create class instance to load in the MNIST data\n",
        "\n",
        "c) create data loader object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnTmL2PH2uaU"
      },
      "source": [
        "## 1a) Create class that does the loading and pre-processing of the MNIST data\n",
        "\n",
        "- `__init__`: stores MNIST filepath, data transformation and filtered MNIST dataframe\n",
        "- `filter_by_label`: filters for images with the label = [insert [0,9] label]\n",
        "- `__len__`: returns total number of images in the filtered dataset\n",
        "- `__getitem__`: retrieves specific image and its label from the dataset based on the provided index. It normalises pixel values, reshapes the image, applies any specified transformations & returns the processed image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJ8SAMtyGiMX"
      },
      "outputs": [],
      "source": [
        "class DigitsDataset(Dataset):\n",
        "    \"\"\"Pytorch dataloader for the Optical Recognition of Handwritten Digits Data Set\"\"\"\n",
        "\n",
        "    def __init__(self, filepath, label=0, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            label (int [0,9], optional): Filter for MNIST images with said specified label.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "            \"\"\"\n",
        "        self.filepath = filepath\n",
        "        self.transform = transform\n",
        "        self.df = self.filter_by_label(label)\n",
        "\n",
        "    def filter_by_label(self, label):\n",
        "        # Use pandas to return a dataframe of only zeros\n",
        "        df = pd.read_csv(self.filepath)\n",
        "        df = df.loc[df.iloc[:, -1] == label]\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = self.df.iloc[idx, :-1] / 16\n",
        "        image = np.array(image)\n",
        "        image = image.astype(np.float32).reshape(8, 8)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Return image and label\n",
        "        return image, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39NfGu8wCsnk"
      },
      "source": [
        "## 1b) create class instance to load in the MNIST data\n",
        "This data is filtered by the label kwarg in the DigitDataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R9DB1blcIQ9F"
      },
      "outputs": [],
      "source": [
        "transform_to_pytorch_tensor = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "dataset = DigitsDataset(\n",
        "    filepath = \"MNIST_images.tra\",\n",
        "    transform = transform_to_pytorch_tensor\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8zMwPqZBwUG"
      },
      "source": [
        "see what's in our class instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "964z9cFsB2cf",
        "outputId": "2f7d35a1-f5d6-4074-cf84-abf6f4582ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.6250, 1.0000, 0.3750, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.4375, 1.0000, 0.5000, 1.0000, 0.3125, 0.0000, 0.0000],\n",
              "          [0.0000, 0.6875, 1.0000, 0.0000, 0.3750, 0.8750, 0.1875, 0.0000],\n",
              "          [0.0000, 0.7500, 0.7500, 0.0000, 0.0000, 0.6875, 0.6875, 0.0000],\n",
              "          [0.0000, 0.7500, 0.7500, 0.0000, 0.0000, 0.5000, 0.7500, 0.0000],\n",
              "          [0.0000, 0.4375, 0.9375, 0.0625, 0.0000, 0.8125, 0.6875, 0.0000],\n",
              "          [0.0000, 0.0000, 1.0000, 0.5000, 0.6250, 0.9375, 0.1875, 0.0000],\n",
              "          [0.0000, 0.0000, 0.6250, 1.0000, 0.9375, 0.1875, 0.0000, 0.0000]]]),\n",
              " 0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAR0HLfTGHNF"
      },
      "source": [
        "in the above output we can see the feature map and the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsd2Z3kUDMY3"
      },
      "source": [
        "display the first 8 images in the dataset class instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "DD3SLOH_DLmM",
        "outputId": "a35ceabf-f375-4467-c7af-c620f3e6606c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x200 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "IMAGE_SIZE= 8\n",
        "reshaped_image_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
        "\n",
        "plt.figure(figsize=(8,2))\n",
        "\n",
        "for i in range(8):\n",
        "    image = dataset[i][0].reshape(reshaped_image_shape)\n",
        "    plt.subplot(1, 8, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image.numpy(), cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUUOK8zaHKZe"
      },
      "source": [
        "to change the digits printed, change the label kwarg in the DigitDataset class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51EJy9vUGQxK"
      },
      "source": [
        "## 1c) create data loader object\n",
        "\n",
        "dataloaders efficiently load date in batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oG-T9naRCdoP"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    drop_last = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o5ceqNUG8tr"
      },
      "source": [
        "# 2) Model Building\n",
        "\n",
        "a) Build class for the classical discriminator\n",
        "\n",
        "b) Building the quantum generator\n",
        "- i) define the quantum variables\n",
        "- ii) define the quantum device\n",
        "- iii) define the qunatum circuit\n",
        "- iv) define the partial measurement process\n",
        "- v) create quantum generator class to use during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRW_ZMRMHyhO"
      },
      "source": [
        "## 2a) Build class for the classical discriminator\n",
        "\n",
        "- fully connected NN with two hidden layers\n",
        "- sigmoid output => probability of an input being classified as real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YKMfcs35J3wi"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Fully connected classical discriminator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__() # calls the constructer of the parent class (nn.Module)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Inputs to first hidden layer (num_input_features -> 64)\n",
        "            nn.Linear(IMAGE_SIZE * IMAGE_SIZE, 64),\n",
        "            nn.ReLU(),\n",
        "            # First hidden layer (64 -> 16)\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            # Second hidden layer (16 -> output)\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGFyFTxJKUUF"
      },
      "source": [
        "## 2b) building the quantum generator\n",
        "\n",
        "Quantum generator consists of `n_generators` sub-generators, each comprised of `n_qubits` qubits\n",
        "\n",
        "Sub-generator circuit architecture:\n",
        "\n",
        "<img src=\"https://pennylane.ai/_images/qcircuit.jpeg\" width=\"500\">\n",
        "\n",
        "---\n",
        "\n",
        "i) **state embedding**: a latent vector, $z \\in \\mathbb{R}^N$, is sampled from a uniform distn in the interval $[0, \\pi/2)$ and sent to all sub-generators\n",
        "\n",
        "$z$ --> $|z\\rangle$ (state embedding) by applying the RY gates. Each element of z determines the rotation angle of the RY gate.\n",
        "\n",
        "---\n",
        "\n",
        "ii) **parameterised layers**: a set of parameterised RY gates apply LINEAR (because they're unitary) TRANSFORMATIONS to the quantum state, followed by control Z gates (to introduce entanglement). This layer is repeated `q_depth` times.\n",
        "\n",
        "---\n",
        "\n",
        "iii) **Non-linear transform**: For non-simple generative tasks we need a non-linearity.\n",
        "\n",
        "Ancillary qubits and partial measurements are used to introduce NON-LINEARITY.\n",
        "\n",
        "Partial measurement: measure ONLY the ancillary qubits. This collapses them into classical values. We don't care about those values though so just discard them.\n",
        "\n",
        "The act of measuring the ancillary qubits and collapsing them to classical values forces a non-linear transformation on the remaining qubits. We then measure these remaining qubits to obtain sub-generator output $\\boldsymbol{g^{(i)}}$, the output for a given patch of pixels. Normalisation, causes the sum of all its elements to sum to 1\n",
        "\n",
        "---\n",
        "\n",
        "iv) **post processing**: all the elements summing to one makes it difficult to map them to pixel intensities\n",
        "\n",
        "$\\tilde{x}(i) = \\frac{g(i)}{\\max_k g(i)_k}$\n",
        "\n",
        "this solves the issue by scaling it so the largest values becomes 1 and all other values scale proportionally\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdjmV6ldb7In"
      },
      "source": [
        "### 2b) i) define quantum variables - as per the diagram in the above markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5saS53R9s2G"
      },
      "source": [
        "potentially add grid search for these hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J569xl1mJ3yt"
      },
      "outputs": [],
      "source": [
        "n_qubits = 5\n",
        "n_a_qubits = 1\n",
        "q_depth = 6\n",
        "n_generators = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CBCslgkcrcX"
      },
      "source": [
        "### 2b) ii) define the quantum device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kum6J7AnJ304",
        "outputId": "3d0ca499-8131-483c-a632-9de3d8276f27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "\n",
        "# Enable CUDA device if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4nvaFV7dl6O"
      },
      "source": [
        "### 2b) iii) define the quantum circuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ikXIuHasJ32z"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, diff_method=\"parameter-shift\") # recall the parameter shift differentiation method from lectures, differentiation needed for backprop\n",
        "def quantum_circuit(noise, weights):\n",
        "\n",
        "    weights = weights.reshape(q_depth, n_qubits)\n",
        "\n",
        "    # State embedding\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(noise[i], wires=i)\n",
        "\n",
        "    # Repeated layer\n",
        "    for i in range(q_depth):\n",
        "        # Parameterised layer\n",
        "        for y in range(n_qubits):\n",
        "            qml.RY(weights[i][y], wires=y)\n",
        "\n",
        "        # Control Z gates\n",
        "        for y in range(n_qubits - 1):\n",
        "            qml.CZ(wires=[y, y + 1])\n",
        "\n",
        "    return qml.probs(wires=list(range(n_qubits)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti2hLBDVdxxF"
      },
      "source": [
        "### 2b) iv) define the partial measurement process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PjK8QVbrdxMV"
      },
      "outputs": [],
      "source": [
        "def partial_measure(noise, weights):\n",
        "    # Non-linear Transform\n",
        "    probs = quantum_circuit(noise, weights)\n",
        "    probsgiven0 = probs[: (2 ** (n_qubits - n_a_qubits))]\n",
        "    probsgiven0 /= torch.sum(probs)\n",
        "\n",
        "    # Post-Processing\n",
        "    probsgiven = probsgiven0 / torch.max(probsgiven0)\n",
        "    return probsgiven"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "claNHS8qeeT3"
      },
      "source": [
        "### 2b) v) create a quantum generator class to use during training\n",
        "\n",
        "- `__init__`: initialises the quantum generator, holds container for the learnable weights that will updated during training (`self.q_params`)\n",
        "- `forward`: iterates over `self.q_params` list which contains the paramters for each sub-generator used to generate the output patches, the patches are concatenated together to form a full image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KNN-JD7nJ342"
      },
      "outputs": [],
      "source": [
        "class PatchQuantumGenerator(nn.Module):\n",
        "    \"\"\"Quantum generator class for the patch method\"\"\"\n",
        "\n",
        "    def __init__(self, n_generators, q_delta=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_generators (int): Number of sub-generators to be used in the patch method.\n",
        "            q_delta (float, optional): Spread of the random distribution for parameter initialisation.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.q_params = nn.ParameterList(\n",
        "            [\n",
        "                nn.Parameter(q_delta * torch.rand(q_depth * n_qubits), requires_grad=True)\n",
        "                for _ in range(n_generators)\n",
        "            ]\n",
        "        )\n",
        "        self.n_generators = n_generators\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        # Initialise empty pytorch Tensor to store the generated images - x.size(0) is the batch size.\n",
        "        images = torch.Tensor(input_batch.size(0), 0).to(device)\n",
        "\n",
        "        # Iterate over all sub-generators\n",
        "        for params in self.q_params:\n",
        "\n",
        "            # Create a Tensor to 'catch' a batch of the patches from a single sub-generator\n",
        "            PATCH_SIZE = 2 ** (n_qubits - n_a_qubits)\n",
        "            patches = torch.Tensor(0, PATCH_SIZE).to(device) # initialise empty pytorch tensor to store the generated patches\n",
        "            for elem in input_batch:\n",
        "                q_out = partial_measure(elem, params).float().unsqueeze(0)\n",
        "                patches = torch.cat((patches, q_out))\n",
        "\n",
        "            # Each batch of patches is concatenated with each other to create a batch of images\n",
        "            images = torch.cat((images, patches), 1)\n",
        "\n",
        "        return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWLSLqMekl4"
      },
      "source": [
        "# 3) Training + Evaluation\n",
        "\n",
        "a) define learning rates and number of training iterations\n",
        "\n",
        "b) execute training process\n",
        "\n",
        "c) evaluation: plot how the generated images evolved throughout training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxquusP8erje"
      },
      "source": [
        "## 3a) define learning rates and number of training iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WYu1hzGVJ367"
      },
      "outputs": [],
      "source": [
        "lrG = 0.3  # Learning rate for the generator\n",
        "lrD = 0.01  # Learning rate for the discriminator\n",
        "num_iter = 500  # Number of training iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6RG8MTbfH-k"
      },
      "source": [
        "## 3b) Execute training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqb8PyqyJ386",
        "outputId": "3d26fc66-5bc4-4ad2-ed33-fec3b10d8418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 10, Discriminator Loss: 1.356, Generator Loss: 0.597\n",
            "Iteration: 20, Discriminator Loss: 1.325, Generator Loss: 0.621\n",
            "Iteration: 30, Discriminator Loss: 1.333, Generator Loss: 0.615\n",
            "Iteration: 40, Discriminator Loss: 1.304, Generator Loss: 0.633\n",
            "Iteration: 50, Discriminator Loss: 1.275, Generator Loss: 0.648\n",
            "Iteration: 60, Discriminator Loss: 1.222, Generator Loss: 0.670\n",
            "Iteration: 70, Discriminator Loss: 1.267, Generator Loss: 0.627\n",
            "Iteration: 80, Discriminator Loss: 1.253, Generator Loss: 0.647\n",
            "Iteration: 90, Discriminator Loss: 1.256, Generator Loss: 0.624\n",
            "Iteration: 100, Discriminator Loss: 1.249, Generator Loss: 0.627\n",
            "Iteration: 110, Discriminator Loss: 1.177, Generator Loss: 0.660\n",
            "Iteration: 120, Discriminator Loss: 1.175, Generator Loss: 0.633\n",
            "Iteration: 130, Discriminator Loss: 1.210, Generator Loss: 0.664\n",
            "Iteration: 140, Discriminator Loss: 1.231, Generator Loss: 0.605\n",
            "Iteration: 150, Discriminator Loss: 1.252, Generator Loss: 0.606\n",
            "Iteration: 160, Discriminator Loss: 1.338, Generator Loss: 0.552\n",
            "Iteration: 170, Discriminator Loss: 1.258, Generator Loss: 0.594\n",
            "Iteration: 180, Discriminator Loss: 1.235, Generator Loss: 0.611\n",
            "Iteration: 190, Discriminator Loss: 1.281, Generator Loss: 0.605\n",
            "Iteration: 200, Discriminator Loss: 1.199, Generator Loss: 0.704\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m outD_fake \u001b[38;5;241m=\u001b[39m discriminator(fake_data)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m errG \u001b[38;5;241m=\u001b[39m criterion(outD_fake, real_labels)\n\u001b[1;32m---> 52\u001b[0m \u001b[43merrG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m optG\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     55\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\torch\\autograd\\function.py:307\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:101\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_backward\u001b[1;34m(ctx, *flat_grad_outputs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_backward\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39mflat_grad_outputs):\n\u001b[0;32m    100\u001b[0m     grad_outputs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_grad_outputs, ctx\u001b[38;5;241m.\u001b[39m_out_struct)\n\u001b[1;32m--> 101\u001b[0m     grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43morig_bw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# None corresponds to the diff of out_struct_holder\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(grad_inputs)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:186\u001b[0m, in \u001b[0;36mExecuteTapes.backward\u001b[1;34m(ctx, *dy)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Torch obeys the dL/dz_conj convention instead of the\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# dL/dz convention of PennyLane, autograd and jax. This converts between the formats\u001b[39;00m\n\u001b[0;32m    185\u001b[0m dy \u001b[38;5;241m=\u001b[39m _recursive_conj(dy)\n\u001b[1;32m--> 186\u001b[0m vjps \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# split tensor into separate entries\u001b[39;00m\n\u001b[0;32m    188\u001b[0m unpacked_vjps \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:304\u001b[0m, in \u001b[0;36mTransformJacobianProducts.compute_vjp\u001b[1;34m(self, tapes, dy)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_vjps(jacs, dy, tapes)\n\u001b[0;32m    300\u001b[0m vjp_tapes, processing_fn \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mgradients\u001b[38;5;241m.\u001b[39mbatch_vjp(\n\u001b[0;32m    301\u001b[0m     tapes, dy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_transform, gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_kwargs\n\u001b[0;32m    302\u001b[0m )\n\u001b[1;32m--> 304\u001b[0m vjp_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvjp_tapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(processing_fn(vjp_results))\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\workflow\\execution.py:209\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     transform_program\u001b[38;5;241m.\u001b[39madd_transform(_cache_transform, cache\u001b[38;5;241m=\u001b[39mcache)\n\u001b[1;32m--> 209\u001b[0m transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m    212\u001b[0m     results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\transforms\\core\\transform_program.py:515\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[1;34m(self, tapes)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argnums[i][j]\n\u001b[1;32m--> 515\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m transform(tape, \u001b[38;5;241m*\u001b[39mtargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtkwargs)\n\u001b[0;32m    516\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[0;32m    518\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:87\u001b[0m, in \u001b[0;36mconvert_to_numpy_parameters\u001b[1;34m(tape)\u001b[0m\n\u001b[0;32m     85\u001b[0m new_ops \u001b[38;5;241m=\u001b[39m (_convert_op_to_numpy_data(op) \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     86\u001b[0m new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m---> 87\u001b[0m new_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_measurements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_params\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnull_postprocessing\u001b[39m(results):\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A postprocesing function returned by a transform that only converts the batch of results\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    into a result for a single ``QuantumTape``.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\tape\\qscript.py:179\u001b[0m, in \u001b[0;36mQuantumScript.__init__\u001b[1;34m(self, ops, measurements, shots, trainable_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    174\u001b[0m     ops: Optional[Iterable[Operator]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     trainable_params: Optional[Sequence[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ):\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m ops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m measurements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(measurements)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shots \u001b[38;5;241m=\u001b[39m Shots(shots)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:85\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@transform\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_numpy_parameters\u001b[39m(tape: QuantumScript) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[QuantumScriptBatch, PostprocessingFn]:\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms a circuit to one with purely numpy parameters.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     new_ops \u001b[38;5;241m=\u001b[39m (\u001b[43m_convert_op_to_numpy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     86\u001b[0m     new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m     87\u001b[0m     new_circuit \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[0;32m     88\u001b[0m         new_ops, new_measurements, shots\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mshots, trainable_params\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mtrainable_params\n\u001b[0;32m     89\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:31\u001b[0m, in \u001b[0;36m_convert_op_to_numpy_data\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Use operator method to change parameters when it become available\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_new_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\ops\\functions\\bind_new_parameters.py:50\u001b[0m, in \u001b[0;36mbind_new_parameters\u001b[1;34m(op, params)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new operator with updated parameters\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mThis function takes an :class:`~.Operator` and new parameters as input and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    .Operator: New operator with updated parameters\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39mparams, wires\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mwires, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(op\u001b[38;5;241m.\u001b[39mhyperparameters))\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# operation is doing something different with its call signature.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     new_op \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(op)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\capture\\capture_meta.py:89\u001b[0m, in \u001b[0;36mCaptureMeta.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enabled():\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# when tracing is enabled, we want to\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# use bind to construct the class if we want class construction to add it to the jaxpr\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_primitive_bind_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\ops\\qubit\\parametric_ops_single_qubit.py:177\u001b[0m, in \u001b[0;36mRY.__init__\u001b[1;34m(self, phi, wires, id)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, phi: TensorLike, wires: WiresLike, \u001b[38;5;28mid\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\operation.py:1868\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, wires, id, *params)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1864\u001b[0m     \u001b[38;5;241m*\u001b[39mparams: TensorLike,\n\u001b[0;32m   1865\u001b[0m     wires: Optional[WiresLike] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1866\u001b[0m     \u001b[38;5;28mid\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1867\u001b[0m ):\n\u001b[1;32m-> 1868\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;66;03m# check the grad_recipe validity\u001b[39;00m\n\u001b[0;32m   1871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_recipe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1872\u001b[0m         \u001b[38;5;66;03m# Make sure grad_recipe is an iterable of correct length instead of None\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\operation.py:1169\u001b[0m, in \u001b[0;36mOperator.__init__\u001b[1;34m(self, wires, id, *params)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim_params: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m _UNSET_BATCH_SIZE\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(p) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params)\n\u001b[1;32m-> 1169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\operation.py:1482\u001b[0m, in \u001b[0;36mOperator.queue\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueue\u001b[39m(\u001b[38;5;28mself\u001b[39m, context: QueuingManager \u001b[38;5;241m=\u001b[39m QueuingManager):\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Append the operator to the Operator queue.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\benat\\miniconda3\\envs\\qgan_env\\lib\\site-packages\\pennylane\\queuing.py:313\u001b[0m, in \u001b[0;36mQueuingManager.append\u001b[1;34m(cls, obj, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Append an object to the queue(s).\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m        obj: the object to be appended\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecording\u001b[49m():\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mactive_context()\u001b[38;5;241m.\u001b[39mappend(obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "discriminator = Discriminator().to(device)\n",
        "generator = PatchQuantumGenerator(n_generators).to(device)\n",
        "\n",
        "# Binary cross entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimisers - stochastic grad descent\n",
        "optD = optim.SGD(discriminator.parameters(), lr=lrD)\n",
        "optG = optim.SGD(generator.parameters(), lr=lrG)\n",
        "\n",
        "real_labels = torch.full((BATCH_SIZE,), 1.0, dtype=torch.float, device=device)\n",
        "fake_labels = torch.full((BATCH_SIZE,), 0.0, dtype=torch.float, device=device)\n",
        "\n",
        "# Fixed noise allows us to visually track the generated images throughout training\n",
        "fixed_noise = torch.rand(8, n_qubits, device=device) * math.pi / 2\n",
        "\n",
        "# Iteration counter\n",
        "counter = 0\n",
        "\n",
        "# Collect images for plotting later\n",
        "results = []\n",
        "\n",
        "while True:\n",
        "    for i, (data, _) in enumerate(dataloader):\n",
        "\n",
        "        # Data for training the discriminator\n",
        "        data = data.reshape(-1, IMAGE_SIZE * IMAGE_SIZE)\n",
        "        real_data = data.to(device)\n",
        "\n",
        "        # Noise follwing a uniform distribution in range [0,pi/2)\n",
        "        noise = torch.rand(BATCH_SIZE, n_qubits, device=device) * math.pi / 2\n",
        "        fake_data = generator(noise)\n",
        "\n",
        "        # Training the discriminator\n",
        "        discriminator.zero_grad()\n",
        "        outD_real = discriminator(real_data).view(-1)\n",
        "        outD_fake = discriminator(fake_data.detach()).view(-1)\n",
        "\n",
        "        errD_real = criterion(outD_real, real_labels)\n",
        "        errD_fake = criterion(outD_fake, fake_labels)\n",
        "        # Propagate gradients\n",
        "        errD_real.backward()\n",
        "        errD_fake.backward()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        optD.step()\n",
        "\n",
        "        # Training the generator\n",
        "        generator.zero_grad()\n",
        "        outD_fake = discriminator(fake_data).view(-1)\n",
        "        errG = criterion(outD_fake, real_labels)\n",
        "        errG.backward()\n",
        "        optG.step()\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "        # Show loss values\n",
        "        if counter % 10 == 0:\n",
        "            print(f'Iteration: {counter}, Discriminator Loss: {errD:0.3f}, Generator Loss: {errG:0.3f}')\n",
        "            test_images = generator(fixed_noise).view(8,1,IMAGE_SIZE,IMAGE_SIZE).cpu().detach()\n",
        "\n",
        "            # Save images every 50 iterations\n",
        "            if counter % 50 == 0:\n",
        "                results.append(test_images)\n",
        "\n",
        "        if counter == num_iter:\n",
        "            break\n",
        "    if counter == num_iter:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTVIp1tzfc5S"
      },
      "source": [
        "## 3c) plot how the generated imgaes evolved throughout training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "XmT9z1RhJ3-9",
        "outputId": "4caee03c-3cfc-469c-98d7-a70cab728aa3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAACfCAYAAAB+1a+kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9jElEQVR4nO2dd3hU1br/3yGEkEIJNQldMNKLUqRJE5QiCscGIkVR4KpcbMjPIwfEBgTQY+GiKHDhgIJcsCAcW6QdQAQUUaQXIwGNAakBksz6/aEzZ+/9fiezJ5kQ4vl+nifPM/nOmr3fWXvttfaavb/r9RhjjBBCCCGEEEJIGClR1AEQQgghhBBC/nxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsMOJBiGEEEIIISTscKJBCCGEEEIICTucaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7IQ00Zg3b554PB7ZsmWLX1u5cqVMnDgx3HGFTF5x1K5dW4YOHXpJ4xEROXTokHg8Hvj3zjvvqPIHDhyQ/v37S/ny5SUuLk66d+8u27Ztu+RxE0LIpYLjSug89dRT0qdPH6lWrZp4PJ484whlXHnnnXekefPmUrp0aUlKSpIxY8bImTNnCulbEEL+EyjwHY2VK1fK008/HY5YCi2O5cuXy/jx4y9xRP/moYceko0bN9r+unfvbiuTkZEhHTt2lD179sicOXNkyZIlcv78eencubPs3r27iCInhJBLD8eVvHnxxRclMzNT+vbtK6VKlQpYLpRxZeHChTJgwABp1aqVrFq1SiZMmCDz5s2T/v37F/bXIYT8iSlZ1AEE4ty5cxITExOWbbVo0SIs28kvNWvWlGuvvTbPMikpKZKRkSEbNmyQWrVqiYhIhw4dpG7duvK3v/1NFi9efClCJYSQPy1/lnHl9OnTUqLE778TLliwIGA5t+NKbm6uPP7449KjRw+ZPXu2iIh06dJFypQpI3fddZesWrVKevbsWcjfihDyZ6RAdzSGDh0qr732moiI7bGgQ4cOiYiIMUZmzpwpzZs3l+joaImPj5dbb71VDhw4YNtO586dpXHjxrJ27Vpp166dxMTEyD333CMiIosXL5YePXpIYmKiREdHS4MGDWTcuHFy9uxZ13GgW9w//vijDBo0SKpUqSJRUVHSoEEDmT59uni9Xn8Z36NP06ZNkxkzZkidOnUkLi5O2rZtK5s2bSpI1SmWL18uXbt29Q8GIiJly5aV/v37y4cffig5OTlh3R8hhFyOcFwJjm+SEQy348qmTZvk6NGjMmzYMNvnb7vtNomLi5Ply5e72h8hhDgp0B2N8ePHy9mzZ2Xp0qWyceNGv56YmCgiIiNGjJB58+bJ6NGjZcqUKXL8+HGZNGmStGvXTrZv3y5Vq1b1f+bo0aMyaNAgGTt2rDz//PP+jnTv3r3Sq1cvGTNmjMTGxsquXbtkypQpsnnzZklNTXUVh5OMjAxp166dXLx4UZ555hmpXbu2rFixQh577DHZv3+/zJw501b+tddek/r168tLL73k31+vXr3k4MGDUq5cuaD1NHnyZHnyySelZMmScvXVV8vYsWOlb9++/vezsrJk//790q9fP/XZpk2bSlZWlhw4cECSk5OD7osQQoozHFfcjSvBCGVc+e677/y6lcjISKlfv77/fUIICRkTAnPnzjUiYr766iu/9sADDxi0mY0bNxoRMdOnT7fpaWlpJjo62owdO9avderUyYiI+fzzz/Pcv9frNdnZ2WbNmjVGRMz27duDxmGMMbVq1TJDhgzx/z9u3DgjIubLL7+0lRs1apTxeDxm9+7dxhhjDh48aETENGnSxOTk5PjLbd682YiIefvtt/OMNz093dx3331myZIlZt26dWbhwoXm2muvNSJiZs+e7S935MgRIyLmhRdeUNtYtGiRERGzYcOGPPdFCCHFEY4rv+N2XHESGxtri8NHKOPKc889Z0TEHD16VJXt0aOHSU5ODikmQgjxUWjL265YsUI8Ho8MGjRIcnJy/H8JCQnSrFkzWb16ta18fHy8dO3aVW3nwIEDMnDgQElISJCIiAiJjIyUTp06iYjIDz/8kK/YUlNTpWHDhtK6dWubPnToUDHG+H/R8tG7d2+JiIjw/+/71efw4cN57icxMVHeeOMNue2226RDhw4ycOBAWbt2rbRo0ULGjRunHofyeDwBt5XXe4QQ8p8Ax5XQCWVcCVSW4w8hJL8Umhn8559/FmOM7Ta2lSuuuML2P7odfebMGenYsaOULl1ann32WUlOTpaYmBhJS0uT/v37S1ZWVr5iy8zMlNq1ays9KSnJ/76VihUr2v6PiooSEcnX/iMjI+WOO+6QcePGyd69e6VBgwYSHx8vHo9H7VdE5Pjx4yIiUqFChZD3RQghfyY4rrgnlHHFF0tmZqaq2+PHj3P8IYTkm0KbaFSqVEk8Ho+sW7fO34FacWroF5PU1FRJT0+X1atX+39tEhH57bffChRbxYoV5ejRo0pPT0/3x16YGGNE5N+GvujoaKlXr57s2LFDld2xY4dER0erAZQQQv7T4LjinlDGlSZNmvj1hg0b+svl5OTIrl27ZMCAAZcmaELIn44CPzoV6FeYPn36iDFGjhw5Ii1btlR/vo4tL3yDhHPweP31113HgejWrZvs3LlTJS2aP3++eDwe6dKlS9Bt5Jfs7GxZvHixVKpUSerVq+fX+/XrJ6mpqZKWlubXTp8+LcuWLZO+fftKyZKX7UrEhBASVjiuhAe340qbNm0kMTFR5s2bZ/v80qVL5cyZM8ylQQjJNwW+evV17FOmTJGePXtKRESENG3aVNq3by/333+/DBs2TLZs2SLXXXedxMbGytGjR2X9+vXSpEkTGTVqVJ7bbteuncTHx8vIkSNlwoQJEhkZKQsXLpTt27e7jgMlM3r44Ydl/vz50rt3b5k0aZLUqlVLPvroI5k5c6aMGjUqbKs7PfLII5KdnS3t27eXhIQESUtLk1deeUW++eYbmTt3ru353Mcee0wWLFjgjykqKkomT54s58+fvywy5BJCyKWC40rerFmzRjIyMkTk9xwYhw8flqVLl4qISKdOnaRy5coi4n5ciYiIkKlTp8rdd98tI0aMkAEDBsjevXtl7Nix0r17d7nxxhvDFjsh5D+MUJzjaHWQCxcumOHDh5vKlSsbj8djRMQcPHjQ//6cOXNMmzZtTGxsrImOjjZ169Y1gwcPNlu2bPGX6dSpk2nUqBHc54YNG0zbtm1NTEyMqVy5shk+fLjZtm2bEREzd+5cV3E4VwcxxpjDhw+bgQMHmooVK5rIyEhz1VVXmZSUFJObm+sv41sdJCUlRcUlImbChAl51tdbb71lWrdubSpUqGBKlixp4uPjzQ033GA+/vhjWH7fvn3mlltuMWXLljUxMTGmW7duZuvWrXnugxBCijMcV/6Nm3HF991EBP598cUXtrKhjCuLFi0yTZs2NaVKlTIJCQlm9OjR5vTp00HjIYSQQHiM+cMwQAghhBBCCCFhotCWtyWEEEIIIYT858KJBiGEEEIIISTscKJBCCGEEEIICTucaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7LhK2Of1eiU9PV3KlCnjz6p6uWCMkdOnT0tSUpKUKKHnTYy9cCjOsYvkHX9xjl3k8o6fsRcNwWIvCopzfTH2wqE4xy7CcaWoYOxFg+txxU2yjbS0tIDJgS6Xv7S0NMbO2MMSf3GOvbjEz9gvr9iLguJcX4ydsYcaf3GOvbjEz9gvr9h9uLqjUaZMGRERSUtLk7Jly/r1xMREVfb8+fNKq1KlitJKlSqltF9++UVpUVFReX7W6/VKZmamP8ZAsX/55ZcSFxfn11u3bq3Knj17VmmVKlVS2unTp5V24cIFuH83BIv93nvvtX3nOXPmqLJopotiP3bsmNJycnKUFhMTo7Rz584FjDGQPmTIEFvs8+fPV2Xd1l2g2b4TVBcmQF5KFL9PW7p0qa0eevXqpcqWLKlPIVSfERERSsvNzYUxuSVY3a9YsUJiY2P9+rvvvqvKLlq0SGkJCQlKQ8f++PHjSjty5IjS4uPj/a+NMWKMCRq7s69p06aNKnvgwAGlXbx4UWmlS5dWGuqn3LavUGO3fn8fqP/r1q2b0n744QeloT4Rna9169b1v87Ozpbly5cHjL0o8MWSnJxsOz/27NmjykZHRyutX79+Snv11VeVNnDgQKU9+uijSjt48KD/dVZWljz44INBj3WdOnVs7ca6DR8tW7ZU2pYtW5RWp04dpaExaffu3XnuIzc3Vw4cOBA0die33nqr0tatW6e08uXLK61cuXJKq127ttJmz56ttCuuuML/2uv1yokTJ0KOvUKFCkq78sorlbZr1y6lodh//PFHpZ08eVJp9erVs/2f1/WIT6tdu7atzaA+E40X6Bx4//33ldaxY0el/fbbb0q75pprVOxu2411jLUePx+o/tB3ctafiMipU6eUtmPHDqWh4xYs9tjYWFvsaPxG40VGRobSqlWrpjS37aZy5cr+18YYyc7ODrnNN2rUSGmHDx9W2m233aa05ORkpaHxD7Ul635PnTolNWrUCDquuJpo+A5M2bJlbQMouqBDGvoCSCvI9gLdUvLpcXFxAU+UvChInMHwXfwGi71UqVK2i4tw11NBvo+b2K0XVQW59VeQmAJNNPL67jExMbYL9XDHVFCC1X1sbKxtco0uUNE20IDgti1Z+4dA5YwxQWN39jUopoK05cJs8/ntJyMjI5WG6h3VBRow0WTmcrr17oslIiLC9p3c1hf6fqj9oXq1nhc+0GQt2LEuUaJE0NjRsSnIeYe+o9vzIy893O0PbQ/Fnp/x3PkabcNtvbt9lNBt7IH2Y20z1s8VZDxH7dhtv4yOY6DPW3WPx2MrU5C+uSBtPq8YA+nO2Aty3VSQdhPK+BNId1vvqJ9Ekym37cvt97FtO893CSGEEEIIISQfuLqj4aNBgwa2WQ96/AA9DvLzzz8rDd32QrMidJvWehsw0C/VTqpXr26biaFHItAvWug7ojhr1KihtMWLFyvt8ccf97/OycmRTZs2BQ76D/bu3Wv7dQY9moM09BgJqs9mzZop7dNPP1Wa8xEYdEvQifPXG3S80C9fqB2hWTh6tAB91vlYgtfrhbc5rbRv3z7oLymoHSEqVqyoNHReoF8Qzpw542ofTvr06WNrqyhW9EgUunWN6tTtr7f5eURs586dtrpAx9ntI3eofWVnZysNPVo2YMAA/2tjjKt9Vq9e3VY3qM1nZWUpbdWqVUpDt6TRowpJSUlKsz7iib7v5QJ6PMwJelz1rbfeUtr//d//KQ218dTUVKVZ26nbcSUtLc12rFFb379/v9LQuYi+I+rDt23bpjTrOOW2T3L+uovqDp3P6DEc9BgHOu/QsbaeC27r3VkWPcaJHq1EfSkaE9GvuydOnFCa83i7qfsPPvjAdl6jR8xQPaBz+Prrr1caisHNUyVu6z4qKsrWbjIzM1UZdB6gGL7//nulofjR+Bmsj0VkZWXZPoeum9yOf+gxJQS6vrIey1DavBX0OBnaFnpcEZ3XiGDtxm3svKNBCCGEEEIICTucaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7IRkBu/Ro4dtqax//etfqgxabxiZx5BBJi0tTWnIcJMfY2ONGjWCGmOR8QWZx9wuodihQwelWY1nbk17qampttjRmuHIDIdyZqAl0davX680ZIy3GmHdmoDeeOMNW+zW9aN9oDaD4kTHHZnw0fFxmrncxJ+QkGCLHeWXcFvHv/76q9LQsnPIuOrMr5CTkyNr1qzBQVto0qSJzfSF8hOgWFEMyLCIvjsyr1r3YYxx1e7bt28fdPlKFDvaNjJeI9P94MGDlWY9RqGYwa2xoT4ELTKB6hOd60ePHlXa119/rTSr0TG/hsNLQfXq1W3H97rrrlNl/vGPf7jaVsOGDZX2t7/9TWn9+/dXmrXtuK0v1N6doG2hOHfu3Km0CRMmKK19+/ZKs44/bmP35bTxgXIauDHqi+C8IGiBgttvvx3GgV7nhdPIjvpSZOCtVauW0pBZf/ny5UpDxmtnvG7ib9y4se1/lGfl0KFDSkN5nD766COlpaenKw3lFHEu5nLq1CnY3zhx9l1ucxK5XVgHHUt0nuWnT3PzGZT3DV1T7Nu3T2kvvfSS0ubOnas063WQ1+uF10BOIiIibPWFzleUYweNiW6vV9F1Rn4Wb+AdDUIIIYQQQkjY4USDEEIIIYQQEnY40SCEEEIIIYSEHU40CCGEEEIIIWEnJDN4rVq1bNmZY2NjVRlkooqOjlYaMjQiDZmAxowZ43994cIFmTVrVsCYfVx55ZU2gybKqogyefft21dp77//vtKQgRGVs8Zw7tw5ueOOOwIH/QeRkZFBs1miONeuXas0txmWkYHIaijzer0w86qTMmXK2GJH2bAXLlyotPHjxyvNmpncBzIjoYzf/fr1s/2fnZ0NjXRWjh07ZjOBIZMaMo6hNnvVVVcpDdXfxIkTlbZixQrb/8hAh9i8ebOtLPrcuHHjlJaSkqI0t1lQUbspV66c/7UxBmZAdtK6dWubkR0Z70aPHq20J598Umldu3ZVGjJoo0URbr75Zv/r7OxsmL3bycmTJ21myMcff1yV+fvf/660Bx98UGmffPKJ0pBRFLU5a7tx29cUBfXr17eZExcsWKDKPPHEE0pDGZ2dRlsR3J6nT5+uNOtiD+fOnZO77rorYMw+SpYsaTuv0IIVkydPVtrLL7+sNJTxHZnBZ8yYoTRrpmmv1wvbtxOnuRRlC0bn8yOPPKK0F198UWkffvih0qZMmaK0JUuW+F/n5ubChQ2cOI3syHyMxhp03FGfgc47ax3ntd9gnDx50jauoH4ZjWE1a9ZUGmrvqI6RCf/555+3/Y/M2ghnu0HGYrSgSJMmTZT23XffKQ1tb+jQoUqzLhBhjFHmdkR0dLQtdvSdkZm+evXqSrOOaz5++eUXpaEFcKwLJLk1gzsXNxg4cKAqs337dqUtXbpUaeja/eOPP1Za7969ldaiRQv/6wsXLsD+1QnvaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7HCiQQghhBBCCAk7IZnBn376aZuRBplhUBZwlGUaGXtRJk9kILKakt1mCd+6dWvQMjfddJOrbXXq1ElpyPDzwgsvKG327Nn+18jUjcjJybHVe8eOHVUZZMJHpipknkZa27ZtlWY1GLrNau6MHWVmdWO6FBHbQgTW7TtBZjin8Rq1NScdOnSA2aetnDhxQmmoTVatWlVpyPT4X//1X0pzZn0/f/68fPbZZ3nGJfJ7fVnrHhkCkZELGYuR6RGZ4xFW45nX63VlBt++fXtQo+pf//pXpSFjJTK5oe0hrMZAN23G9xlrHNOmTVNl0tLSlPbqq6+62j4CHQvrIhyXc2ZwZ1tGfQQyx6I2iY5/Zmam0p599lmlWcczt8fa2f8gw/A999zjalsodtT//Prrr0qzZpd22zc7vyNa2ALVMRrPo6KilFaxYkWlvfbaa0r76aef/K/dtlOnCX/IkCGqDKo7FDvKho3GU7RYjbNfd7NQR/PmzW31Wrt2bVUGXfeg661jx44prUaNGkp79NFHlWZd6ELE/bVUpUqVbPGjRXRQ3aNji747WqBkxIgRSstPf5mbmxs0uzaKHZ1TqM2/+eabSkPmcutiAPntm9955x2l7dy5U2noHEb7RIs2ffrpp0pbt25dnttB8I4GIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsBOSGbxq1ao2Ywkyfj/88MNKu/POO5U2depUpfXq1UtprVq1UprVKHXq1CloknJSuXJlW+wog+MPP/ygNBT7N998ozRkVL733nuVZjXXZGdnuzKpe71em4Hpgw8+UGVQ9llUbtOmTUo7deqU0pCpcd68ef7XWVlZ0LjsxJkhFGUMXbZsmdJQ+0CxowyXKIvwtm3bbP9nZ2fL999/rwO20KpVK5vJ9siRI6oMMs0jkzc6Fsis//TTTyvNaaB0a/Y8f/68rd2gjMvNmzdXGmrfyOSITIeoTWRlZflfuzWPRUVF2faJTPdPPfWU0mbNmqU0lCUZZYRFJnVnBle3WL8nMgOiLNDdunVT2hdffKE0lMl49erVSvvf//1f/2u3/WRRYT3WzsUPRLBBHC3A8e233yoNnY9oQQ/ruZ6TkyO7d+8OHPAfxMbG2mJH/dukSZOUhkzRaExCxwwtpGJdwMFtO/V4PLbYU1NTVRnUTp0La4jgLO2ov2zTpo3Szp4963/t9Xrh8XfiXGQEnffW8crHgw8+qDSUURoZbdHCI05zuZu6L126tM1wjEzYyGgcFxenNHQsUOzoOgONSW7IyMiw1X2PHj1UGTQ2HD58WGmo7p1jtQi+DswPTjP4vn37VBk0JqJrBbQABzo3g41JoZjBrbEj47fVZO4DLXyCzjHUd1WrVk1p1kUELl68KG+99VbggP+AdzQIIYQQQgghYYcTDUIIIYQQQkjY4USDEEIIIYQQEnY40SCEEEIIIYSEHY9x4UTxGQkbNGhgMzEhw0/9+vWV9vLLLysNmY2RORaZa/bs2aO0kydPQiOML/bWrVvbTDEoCyIywyHDDzILJSUlKW3Lli1Ks5p5vF6v/PTTT0Fjj4iIsH0OZa5E2U1//vlnpVmzqvtApkd0HK3lfM0mWOzO7NSo3pEhDDXLpk2bKg1lWE5MTFTaoUOH1PbPnj0L4/fF/tlnn9nM5kuWLFHbRUZ6qwnXx3333ac0t9ncnRl8vV6vHDt2LGjdO99H7QYdD2QKQ2ZPZNAOlhnXbbvp3bu3rS7QuYniRN8RGQm/++47pSHjrTWrdF5txhq783xFC0Wg8xWZZ5EBFLU5VA6Z2wPFXhT46uuFF16w1dH27dtV2ZUrVyotIyNDac5MzSJ4wYgLFy4ozdqejTFy7ty5oMe6fPnytmONxkS0yAhqa2iBApStGxmAEcFiT0xMDLpACjJAu83wjNozylKMjkWw2J0L0wQ7nnlRvXp1paHM8CgzeKDLp7zGFed7yLQ+bNgwpXXu3Flp6Dsi7ccff4RxIkIdV9CYha7vkIay3KPzICEhQWnW4+F2XBk5cqTNaG/Ncu1j//79SkOZ2tFiSKiNWMcQH9Y+w23s1apVs7V5ZOhGCwtYF4rwgcZzNJ6i8xUdn2DjCu9oEEIIIYQQQsIOJxqEEEIIIYSQsMOJBiGEEEIIISTscKJBCCGEEEIICTshZQZPS0uzmViQUWTNmjVKQ2bMjRs3Kg0ZSbt06aI0q1Hq/PnzMJuyk6+++goacKygLKgoq/CAAQOU9t///d9KQxmBrQaeM2fOwMzSTsqXLx80IzuKE5lQd+3apTSUhXT27NlKGzRokP+11+uFRmwnzqzmyMDUuHFjpSFj0qJFi5R2yy23KG3Hjh1Kc2asv3DhgvzP//wPjNnHmDFjbOZiZK49ePCg0pDpbebMmUpbuHCh0t5++22l1axZ0/a/23YzcuRI22IG6HxFpn/URlAm47vuuktpyERpzers9XqhSdTJypUr1cIJTtD5irZ99913K23+/PlKW79+vdLuvPNO/+vs7GyYxd6J07SHFjtAfQMyEqP2hRaoQFmyr7/+ev/r7OxsWbFiReCgi5Dnn3/edqyRoRFlt7UeGx+oj7jjjjuUhjKujxo1yv/6woUL8sorrwQO+g+cfTHqI1DsWVlZSkOLWOzdu1dpwTK8G2NgHE5iYmKCZqhGbQ3tH7XTunXrKq1Zs2ZKs/bXXq/XldndmdUcmdYrVqyoNLRYAOqbr7vuOqX17dtXac7jk5ubC4+ZlWDHTwT31WiRBHQOoLpA2cJvvfVW2/8XL16EY5KT6dOnw2sLK24XrOjXr5/SUD/coUMHpVkzmxtj4DWQkzlz5tjaDTo30UId3377rdLQNd+kSZOUZs2k7cOa/dzr9cLxwElERIStXaBrJNS2WrZsqbR//etfSkMLOqC4rNdc2dnZ8tFHHwUK2Q/vaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7LjyaPj8DE5fA3oeG3kf0DOD6Bk+BHpu1JowxJeoJ1DinECxo/LoOXCkoYQl6Pug52StzxGePXs2YCxW3RkDKu9WQ3Gicr7YrFjj8L0Otd4RqB2hekfPYKLPou/oTOjkS2KTV72hRHmBygbT3NY7eu7S+b3dthvnuYPKuz2HUVxuv2dhtRu3xwM9D++2T7LWoe91YZ2v6Pu4bTfos6HEXhSE0jcjDY0NwY6hD1Rf1j4ir/4hVP1SHH/0fqjtNK+y+YkzWJtE5dz2D27OMbR/1N+hsc5tO3Juz/e/22MeCLefR8nY3CZZdH7Wbf/mHEsL0r7dnpuonHUfbtt8fq8DUTmUJDI//U8423xBrr/dfu98jSvGBWlpaUZELuu/tLQ0xs7YwxJ/cY69uMTP2C+v2IuC4lxfjJ2xhxp/cY69uMTP2C+v2H14jAk+zfa54suUKQNXhipKzB8rbCQlJcGVGhh74VCcYxfJO/7iHLvI5R0/Yy8agsVeFBTn+mLshUNxjl2E40pRwdiLBrfjiquJBiGEEEIIIYSEwuXx0xYhhBBCCCHkTwUnGoQQQgghhJCww4kGIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsMOJBiGEEEIIISTscKJBCCGEEEIICTucaBBCCCGEEELCDicahBBCCCGEkLDDiQYhhBBCCCEk7HCiQQghhBBCCAk7nGgQQgghhBBCwg4nGoQQQgghhJCww4kGIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsBPSRGPevHni8Xhky5Ytfm3lypUyceLEcMcVMnnFUbt2bRk6dOgljcfHU089JX369JFq1aqJx+MJGMfEiRPF4/Gov9KlS8Py77zzjjRv3lxKly4tSUlJMmbMGDlz5kwhfhNCCAk/HFdCY+vWrfLAAw9IkyZNpEyZMlK1alW5/vrrJTU1FZY/cOCA9O/fX8qXLy9xcXHSvXt32bZtGyzLcYUQEm4KfEdj5cqV8vTTT4cjlkKLY/ny5TJ+/PhLHNHvvPjii5KZmSl9+/aVUqVKBS3/z3/+UzZu3Oj/W7t2rSqzcOFCGTBggLRq1UpWrVolEyZMkHnz5kn//v0L4ysQQsglheNKYN5++23ZvHmz3HPPPfL+++/Lm2++KVFRUdKtWzeZP3++rWxGRoZ07NhR9uzZI3PmzJElS5bI+fPnpXPnzrJ7925bWY4rhJDCoGRRBxCIc+fOSUxMTFi21aJFi7BsJz+cPn1aSpT4fT63YMGCoOWvueYaqVSpUsD3c3Nz5fHHH5cePXrI7NmzRUSkS5cuUqZMGbnrrrtk1apV0rNnz/AETwghfyL+DOPK2LFjZdq0aTatV69ecvXVV8ukSZNk8ODBfj0lJUUyMjJkw4YNUqtWLRER6dChg9StW1f+9re/yeLFi0WE4wohpPAo0B2NoUOHymuvvSYiYnvc59ChQyIiYoyRmTNnSvPmzSU6Olri4+Pl1ltvlQMHDti207lzZ2ncuLGsXbtW2rVrJzExMXLPPfeIiMjixYulR48ekpiYKNHR0dKgQQMZN26cnD171nUc6Bb3jz/+KIMGDZIqVapIVFSUNGjQQKZPny5er9df5tChQ+LxeGTatGkyY8YMqVOnjsTFxUnbtm1l06ZNrurIN8kIF5s2bZKjR4/KsGHDbPptt90mcXFxsnz58rDujxBCLiUcV/KmSpUqSouIiJBrrrlG0tLSbPry5cula9eu/kmGiEjZsmWlf//+8uGHH0pOTo6IcFwhhBQeBbqjMX78eDl79qwsXbpUNm7c6NcTExNFRGTEiBEyb948GT16tEyZMkWOHz8ukyZNknbt2sn27dulatWq/s8cPXpUBg0aJGPHjpXnn3/ef4G+d+9e6dWrl4wZM0ZiY2Nl165dMmXKFNm8ebP/mdRgcTjJyMiQdu3aycWLF+WZZ56R2rVry4oVK+Sxxx6T/fv3y8yZM23lX3vtNalfv7689NJL/v316tVLDh48KOXKlStIFSqaNGkiv/zyi1SqVEluuOEGefbZZ6VmzZr+97/77jsREWnatKntc5GRkVK/fn3/+4QQUhzhuBL6uJKTkyPr1q2TRo0a+bWsrCzZv3+/9OvXT5Vv2rSpZGVlyYEDByQ5OZnjCiGk0CjQRKNu3br+Tv3aa6+1vbdp0yaZPXu2TJ8+XR555BG/3rFjR0lOTpYZM2bIlClT/Prx48fl3Xffla5du9q289RTT/lfG2Okffv20qBBA+nUqZN8++230rRp0zzjQMyYMUOOHDkiX375pbRu3VpERG644QbJzc2VWbNmyZgxYyQ5OdlfvkyZMrJixQqJiIgQEZGkpCRp3bq1rFq1Su68805XdRWMunXrynPPPSctWrSQ0qVLy+bNm2Xq1KnyySefyNatW6VatWoiIpKZmSkiIhUqVFDbqFChgv/XNkIIKY5wXAl9XJk4caLs27dP3nvvPb924sQJMcYEHCtE/j2ecFwhhBQWhba87YoVK8Tj8cigQYMkJyfH/5eQkCDNmjWT1atX28rHx8erwUDk9xUzBg4cKAkJCRIRESGRkZHSqVMnERH54Ycf8hVbamqqNGzY0D8Y+Bg6dKgYY9TqHb179/YPBiL//tXn8OHD+do/4u6775Ynn3xSevbsKV26dJEnnnhCVq1aJRkZGTJ16lRV3uPxwO0E0gkhpLjDcUXz5ptvynPPPSePPvqo3Hzzzer9vMYE53scVwgh4abQzOA///yzGGNst7GtXHHFFbb/0e3oM2fOSMeOHaV06dLy7LPPSnJyssTExEhaWpr0799fsrKy8hVbZmam1K5dW+lJSUn+961UrFjR9n9UVJSISL7375bWrVtLcnKy7bldXyyZmZmqbo8fPw5/kSKEkD8DHFfszJ07V0aMGCH333+/pKSk2N6Lj48Xj8ej9ivy+1gh8u87GBxXCCGFRaFNNCpVqiQej0fWrVvn70CtODX0i0lqaqqkp6fL6tWr/b82iYj89ttvBYqtYsWKcvToUaWnp6f7Y79cMMbYDOVNmjQREZEdO3ZIw4YN/XpOTo7s2rVLBgwYcMljJISQSwHHlX8zd+5cGT58uAwZMkRmzZqlvmt0dLTUq1dPduzYoT67Y8cOiY6O9k/MOK4QQgqLAj86FehXmD59+ogxRo4cOSItW7ZUf76OLS98Hadz8Hj99dddx4Ho1q2b7Ny5UyUtmj9/vng8HunSpUvQbVwKNm3aJHv37rU9H9ymTRtJTEyUefPm2couXbpUzpw5wzXPCSHFHo4reTNv3jwZPny4DBo0SN58882Ajzb169dPUlNTbatRnT59WpYtWyZ9+/aVkiV//62R4wohpLAo8B0NX8c+ZcoU6dmzp0REREjTpk2lffv2cv/998uwYcNky5Ytct1110lsbKwcPXpU1q9fL02aNJFRo0blue127dpJfHy8jBw5UiZMmCCRkZGycOFC2b59u+s4UJK8hx9+WObPny+9e/eWSZMmSa1ateSjjz6SmTNnyqhRo2yGvYKyZs0aycjIEJHf1yo/fPiwLF26VEREOnXqJJUrVxYRkWbNmsmgQYOkQYMGfjN4SkqKJCQkyNixY/3bi4iIkKlTp8rdd98tI0aMkAEDBsjevXtl7Nix0r17d7nxxhvDFjshhBQFHFcC8+6778q9994rzZs3lxEjRsjmzZtt77do0cI/QXrsscdkwYIF/piioqJk8uTJcv78eVvGc44rhJBCw4TA3LlzjYiYr776yq9duHDBDB8+3FSuXNl4PB4jIubgwYP+9+fMmWPatGljYmNjTXR0tKlbt64ZPHiw2bJli79Mp06dTKNGjeA+N2zYYNq2bWtiYmJM5cqVzfDhw822bduMiJi5c+e6iqNWrVpmyJAhtu0ePnzYDBw40FSsWNFERkaaq666yqSkpJjc3Fx/mYMHDxoRMSkpKSouETETJkwIWmedOnUyIgL/vvjiC3+5O++809SrV8/ExsaayMhIU6tWLTNy5EiTnp4Ot7to0SLTtGlTU6pUKZOQkGBGjx5tTp8+HTQeQgi5nOC48m/cjCtDhgwJOKY468kYY/bt22duueUWU7ZsWRMTE2O6detmtm7dCrfNcYUQEm48xhhzyWY1hBBCCCGEkP8ICm15W0IIIYQQQsh/LpxoEEIIIYQQQsIOJxqEEEIIIYSQsMOJBiGEEEIIISTscKJBCCGEEEIICTucaBBCCCGEEELCjquEfV6vV9LT06VMmTIBM5AWFcYYOX36tCQlJUmJEnrexNgLh+Icu0je8Rfn2EUu7/gZe9EQLPaioDjXF2MvHIpz7CIcV4oKxl40uB5X3CTbSEtLyzNB0OXwl5aWxtgZe1jiL86xF5f4GfvlFXtRUJzri7Ez9lDjL86xF5f4GfvlFbsPV3c0ypQp439tnVGh2VXJknqT7dq1U9q6deuUZkDuQKRVrVrV/9rr9covv/xii9FKoNjRdkuVKqW0ixcvKq1Ro0ZK+/7775UWaHaaV4xu9JiYGKXl5OS42hcq5xbr9zHGiDEmLPUeFxentDNnziitQoUKSjt+/LjSULtE+3XG6dQqV65s+84///yzKouO8dVXX620zz//XGm1a9dWGjpmJ0+eVJo1zkC68xeQtLQ0VfYvf/mL0sqXL6+0bdu2Ka1KlSpKa9mypdIWLFjgf22MkVOnTgWNvXTp0rbYz58/r8qi4xwZGam0YcOGKW3WrFlKQ8fj0KFDAWMMpEdFRdliQ+0WtaVx48YpLSUlRWmonzp37pzSunbt6n+dk5Mjq1evDhh7URBKLDVr1lRa9erVlbZx40ZX20PjlLVejTFy7ty5kPtmBGqT2dnZSitdurTSULt3S6ixx8bGKi03N9fVvgoSJxofwlHvbuvT7TgdCnmNK25A7T0xMVFpDzzwgNIeffRRpaFxMtCxDbXujxw5orSHHnoIlnWycuVKV+Xq1KmjtD179vhfG2PE6/WGpd0gUBuJj49XWmZmptLcXo8Ei93j8di2FRUVpcqia6lOnTopbenSpXBfTtA5ZB33vV6v/PTTT0Hr19VEw/flnF8UVaDbyUdBbgGhgx5oe4FiRwfabUwRERGuPut2e8Fiz+t1OLRAF+HBPmuMuaT17vaRj1C+Y151VKJEiaD7dNvey5YtqzS0bbfHItC+rbqz7lEMKFZ0YYRiRZ9FnV8o50ZB+xqkoZgQBWlfVt0Zu9v+CnXqBfne6DheTrfeAx1fdA64bX8F6XPz007zu6+CbrMg2wtFvxQx5Wdcye++CrrNguw7lO/ktr2jHx1DuT5yG49TDzauoL4nlH05Keg1V0GPsdtjlJ99+/q7cIyJKKaCjANu9xFse5fHw7qEEEIIIYSQPxWu7mj4qFSpkm02c+rUKVUG3UL59NNPlfbDDz8obf369UpDtwatj/+4vcV51VVX2WbFaP/otuqIESOU1rFjR6XdfffdSrv99tuV9tlnn/lfe71eeKvNiXMm27hxY1Xm9OnTSpszZ47SXnnlFaX94x//UFrnzp2VtmnTJv9rYwx8rCwY9erVU9revXuV9s033yhty5YtSvvoo4+U1qpVK6W9/PLLtv+9Xq9kZGTkFaqcOHEi6C/TSUlJSmvRooXSmjVrpjT0uAvC+YuEMcbVI3Bnz561xd+kSRNVBj3Ws2PHjqAxiIgMGDBAaYsXL1aa9Ra92zs25cqVs9V3QkKCKrN161alvfXWW0pDj57Vr19faY888ojSrP2P23o/f/68rd5/+uknVQbdvXjqqaeUhh5L6Natm9JQ/2N9PKcgj0wWNqVKlQr6CykaBx577DGlTZ8+XWnoUdeePXsqLT/9Wbly5WyxozHxwoULSkOPKaFHjNGYiPoht32JE2vsqG/u0qWL0m666SaljRw5Umm7d+9WWuXKlZX266+/Bo0zGOixovT0dKW1bdtWaWjcR48uofEH7SMYNWrUsB3Dw4cPqzIHDx5U2ieffKI06+NDPlDftmbNGqU526DvccFQQY98tm7dWmlr165VGnokCj2GfuWVVyrNeofHGOPqMb/y5cvb2jx6/Gn//v1KQ+cGGpNq1aqlNHR8rY+GG2NcPXrovNZFxwpdmy5atEhp6PoX9YnTpk1TmnU8dTue844GIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsBOSGfzUqVM2Iw1axxyt8Y6WJkOm8d9++01pTzzxhNKsphi3ZvA9e/YENb7deOONSkM5BZDxEpliypUrpzRkFgyGc9vIPJecnKw0tH4yMiEi+vTpo7Tt27fbYnJjnixRooSt3g8cOKDK9OvXT2nIII5MWllZWUpDRnan8duNiSk7O9sWO2pr1pwuPpCZGpn+kZkLmYSdZtbc3Fy4DyfO74gMYIMHD1bahg0blIZyTKBcJ6jurTlz3JrHfv31V1vdnz17VpW58847lYaMdygXxtGjR5V2/fXXKw3lOwgVlFsEmT3RGujoHEPr5COT7ddff+1/XdC8AIWJM2cKOqdQbhpkGkemSlSHFStWVJrVoOt2oQ6n8b9v375BPyMi8te//tWVhhb5QPUTDlAbmTFjhtLQGI9y6sydO1dp3bt3V9qyZcv8r/M7rqC8NAjUZ6E+Y8qUKUobNWqUq30EIy0tLV/LrT7zzDNKQ7Hv27dPaWjcd/ZtbvvmyMhIW/xvvPGGKuO230ILNfTv319p6HoNfc9gOM9XdM2JiI6OVhq6lpk6darSJk6cqDTrNZzbencumoEWL2natKnS0CIw3333ndKs44WPt99+W2nWa5Tc3FxXdcg7GoQQQgghhJCww4kGIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsJOSGbwmJgYmxkFZWtFplGUmfDdd99VGsouigyzViOfW5OjsxzKqNm+fXulLVmyRGnIhLhgwQKlISOf1XBojHFlBEpMTLR9Dhl+UEZkVJ+rVq1SGjIXoiyb1gy3bg1MJUuWtLUZZEpD2TlRNl1k9ESZXq0ZzH2gbLrBqFq1qu1zyECMMpuiDK4oszbKPosyODtN3G7rvlq1arb4kUEPZY//+OOPlYYMX8gEiBYqcBuvFWc9oOzeV1xxhdLQ+YoWo+jQoYPSNm7cGEqIeWL9zv/v//0/9f7mzZuVNnnyZKWh2FFm8BMnTijNmqU2NzcXlrkcQabbH3/8UWnI0I2M/7Nnz1Yaas9RUVH+127b7IULF2z92wcffKDKoLb21VdfKQ2ZrO+5554840QYY+AiGU7i4+Nt/QPqy2655RaloQUrkLl50qRJSkOZ7q1jjdt6j4iIsO0TZWlG1yK//PKL0lCfO2LECKWhBSmcdWGMgWOXFaeRHY216FjExMQorVq1akpr0KCB0tB1EvrebqhZs6atX7Jm6PYxfPhwpaExGB1vdG2WH+M3wmkGR8cKjctpaWlKQ23+8ccfVxpqc/nBOX6j8+v5559XGmrLL7zwgtK6du2qtJ9++klp1oVH3F5/844GIYQQQgghJOxwokEIIYQQQggJO5xoEEIIIYQQQsIOJxqEEEIIIYSQsBOSGdxpJnz99ddVmV27drnaFjLSXHvttUpbunSp0vKTGdwJMo8hQzcyaiED07Rp05SGYrNmmHRjHBMROXbsWFBDdYUKFZSGspqjeh86dKjSkIH/+PHj/tduTXvO7NqjR49WZSZMmKC0SpUqKQ2ZP2+//XalIVNvfjKx/vbbb7bPJSYmqjKpqalKQ8cdmU+d2cpFRFJSUpT27LPP2v53mz3XGT/KzIrMxij+hg0bKu37779X2tNPP620+fPn27aNDLtOnIbJZs2aqTIoazFql8g8265dO6WtX79eaflpN06Q8W7Lli1KQ98HHQvUDpHJ1pq5Nj+G/EvFqVOnbP+//PLLqszevXuVhuoGHS+UNRoZa63nVH7rC5lzd+/erTSUcR7tE31vaz/sw2rIdRu7s39AC1ag8ReNP6h/Q0by1atXK816XWGMgQvAOMnNzbXFjhY+QZnW3Y6JAwYMUBoy2iIzeDCcfduVV16pyqD26VwURAQv8IFM3k8++aTSnGONMQZe7zg5ceKEzdiNFqIZPHiw0lDdoAUQUIZqtGjJP//5T//r7Oxsee+99wLG7MPj8djqHl1zIgM0Ap0H6Hrk73//u9Ks55rbenfSuHFjpaG+Bpn1URtB2c9RH3vs2DH/a7d9De9oEEIIIYQQQsIOJxqEEEIIIYSQsMOJBiGEEEIIISTscKJBCCGEEEIICTse48LNcerUKSlXrpzSUYZsZHJDZiuUuRQZT5AB2GpE8nq9cvz4cTl58iSMxxe704CFTLDJyclKQ+Z2ZKRp1KiR0pAxyGqW9WUGDxa7iASNPS4uTmkoMzk6jpmZmUpD2bqR4S8csXfu3Flpn332mdLQZ62GMB/Lli1T2qxZs2z/+5o9it8Xe1RUlC12VHco66fbY4EysqO25TR/5hW7NX4Re92j8xBl+XV7DqPzBZlX0YIHocaOjKrIMIkyiCMzHMqei/oaq3k1lHoPhluDHgJ12ah+rJmRvV6vHDhwIGDsRUGg+qpbt67SUMZ5dE6hukHjCtqvtf592bVDPdbIIHrTTTcpDWWwR3G2bNlSaX/5y1+UZjX7um2nzuza6Pugc+zMmTNKQ/WOMtGXKVPG1faCxR4ZGWmLHcWJFh6ZPHmy0lB/t3PnTqVNnTpVaXPnzlWaSN7jivNaBC0gYDXc+kB1jGJH20NmY+ciCW7bTcmSJYPWPVqwAl3zofHzhhtuUNqqVauUlt9xxQoqizLKf/vtt0pDfe4111yjNHQtZb1uye+4gq6HkOZm4RhrHMG2Zx0nvV6vZGZmBh1XeEeDEEIIIYQQEnY40SCEEEIIIYSEHU40CCGEEEIIIWGHEw1CCCGEEEJI2AkpM/iVV15pM4cg4yUy7aHsj71791Zax44dlYYMRFYDlNvMhE6jHTJjooyryLCLTIjIGDRp0qSgcbjBmc0SmUaRMQoZwJAxsU6dOko7e/as0qwZlt1mp/aV9YFi/+qrr1xtp0aNGkobPny40g4fPuxqe8G46aabbMcVtRlkepsyZYrSXnzxRaWhDMgoW3h+sxT37dvXFv8HH3ygygwZMkRpKHM3ykL69ttvK61r165KQ0a+YDjNnqjuW7durTRkXkPnNcqgiozsThO8m2PhNEui89Ct8RtlMK9UqZLSUL9SXDKDd+nSxXZ8P//8c1UGnT8bN25U2quvvqq0pKQkpQXLru62vkqVKmU71sici4ycAwcOVBrqB9G5OGHCBKXl5/g62ykyZV933XVKW7lypdJef/11uH0nKE5r/RhjVKZ4hLOe0Vi0Y8cOpaEFH9CiFk2aNFFafsZuREJCgm1BG7QYCxrP0fF55513lHbfffcpze2xcEOzZs1s/ew333yjyqAs5vfff7/SunfvrrSFCxcqrUuXLkpbu3at/7Vv8YZQQddy27dvV9qKFSuUhhasQVnAExISlGY10Btj5Ny5c0FjLVeunO18RdffqN2iYzFy5EiloTaCFrewXuMzMzghhBBCCCGkyOBEgxBCCCGEEBJ2ONEghBBCCCGEhB1ONAghhBBCCCFhJyQz+LFjx2xmFGSkQVmRkbkLZc1GhtMNGzYozWpQy8nJkfXr1wcOOgDIUGk1A/ro1q2b0pAJ8euvv1YayqZsNVEZY1wZzMaPH2/L4IwylCLDKTLqoLpCBvFp06YpzWpYys3Nle+//z5w0H9QtWpVm/ENZY/cs2eP0pyZvEVE3nzzTaUhA2V0dLTSzp8/HzRWJ8uWLbMdw8qVK6syKLPpzTffrDRrRngfr7zyitIGDx6stB49etj+z8nJkdTUVBy0hQULFtjqu0qVKqrMG2+8oTR0vqIFA0aMGKG09PT0oHG5ISYmxlb3NWvWVGWQGW/UqFFK27p1q9JQ1mKU4TY/BtAaNWrY2rzVlO2jevXqSktLS1PavHnzlPbee+8p7cMPP1Sate/KycmRL774IlDIRYozLpQZfOzYsUpD5zQyJaMxBI01VtOm1+uVgwcP4oAtXLx40dZOUd+DYqpVq5bS0GIXu3btUhpa8MDaN/my9Qaje/futsUili9frsqgNoPqHZng27Ztq7SJEycqzTqOuB1XKlasaDvHkBEYLX7x0EMPKQ0ds9WrVysN9Q9OE7qbMd3ZR6LrBKQ1a9ZMaah9oGsWdBydY7ExBl7TObn66qttC/ygMRgZoJFJHS1G0qpVK6Wh+nBjoHYSFxdn2xZaqAgt7NO+fXulofMALSjSoEEDpVmvzdwaqk+fPm2LHfWTaMEAFCdqN+j6ICUlRWnWRVhycnLg+OqEdzQIIYQQQgghYYcTDUIIIYQQQkjY4USDEEIIIYQQEnZceTR8z5A5nyVDz5YhDT3zjZ7pRElq0Pasya58rwM95xZId/vsNUqs5fY7BosnUL0633fWS0HqHSXiQ886ou9t9YH4XgeL3VnPbr0k6Jlb9Fn0HUNJRJRXXTrfQ20GfR7VsdvviHAeC7dt3lk3buNHdYo+i87X/CRxRLrzfbftBu0fxV6QdhNqm0fl3cYULGFpXvsIpZ8sCkLpm922U1Rf6LnzYMfE99rNuJKf563Rd0R9rtt2mp/YUTtysy+34zl6XhyVC8e44nZMRH2W1evhw229B7omchtPXroTt32g22uWUGK36siX4sTteOE2fuTRyCvGQHp+x3QUE9Lc9jX5uQ50EzsCtWW3Xo5gdRHsfLVuKChpaWlGRC7rv7S0NMbO2MMSf3GOvbjEz9gvr9iLguJcX4ydsYcaf3GOvbjEz9gvr9h9eIwJPp32er2Snp4uZcqUcT2zvFSYP1ZKSEpKgr9MMPbCoTjHLpJ3/MU5dpHLO37GXjQEi70oKM71xdgLh+IcuwjHlaKCsRcNbscVVxMNQgghhBBCCAmFy+OnLUIIIYQQQsifCk40CCGEEEIIIWGHEw1CCCGEEEJI2OFEgxBCCCGEEBJ2ONEghBBCCCGEhB1ONAghhBBCCCFhhxMNQgghhBBCSNj5/wtfnFJxs+1RAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 32 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(10, 5))\n",
        "outer = gridspec.GridSpec(5, 2, wspace=0.1)\n",
        "\n",
        "for i, images in enumerate(results):\n",
        "    inner = gridspec.GridSpecFromSubplotSpec(1, images.size(0),\n",
        "                    subplot_spec=outer[i])\n",
        "\n",
        "    images = torch.squeeze(images, dim=1)\n",
        "    for j, im in enumerate(images):\n",
        "\n",
        "        ax = plt.Subplot(fig, inner[j])\n",
        "        ax.imshow(im.numpy(), cmap=\"gray\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        if j==0:\n",
        "            ax.set_title(f'Iteration {50+i*50}', loc='left')\n",
        "        fig.add_subplot(ax)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvSSPSkkJ4BA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "qgan_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
